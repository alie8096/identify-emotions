احساسات تجربه های شناختی ذهنی هستند که به صورت گسترده ایجاد می‌شوند.
احساسات شامل مجموعه وضعیت روانی هستند که به وسیله احساسات، افکار و رفتار های مختلف به وجود می‌آیند.
افراد در طی فرایند های ارتباطی به صورت مداوم اطلاعات حسی را منتقل می‌کنند.

در تحقیقات شناخت احساسات، یکی از مهم‌ترین مشکلات توصیف علمی وضعیت احساسی و ساخت یک مدل توصیف احساسی است. مدل‌سازی احساسی شامل ایجاد یک مدل ریاضی برای توصیف وضعیت احساسی است که سپس توسط یک سیستم aBCI می‌تواند طبقه‌بندی یا کمیت‌بندی شود.
سیاری از پژوهشگران روش‌های نمایش احساسی مختلفی را پیشنهاد داده‌اند؛ این روش‌ها را می‌توان به مدل‌های احساسی گسسته و مدل‌های احساسی بعدی تقسیم کرد.[[1]](#He,-Z.,-Li,-Z.,-Yang,-F.,-Wang,-L.,-Li,-J.,-Zhou,-C.,-&-Pan,-J.-(2020).-Advances-in-Multimodal-Emotion-Recognition-Based-on-Brain–Computer-Interfaces.-Brain-Sciences,-10(10),-687.-doi:10.3390/brainsci10100687.)

 برای دو مدل احساسی میتوان به مدل  احساسات گسسته  متشکل از چند احساس اصلی  غم، ترس، نفرت،تعجب شادی و خشم بر اساس مدل پیشنهادی Ekman[[2]](#Ekman,-P.E.;-Davidson,-R.J.-The-Nature-of-Emotion:-Fundamental-Questions;-Oxford-University-Press:-Oxford,-UK,-1994.) که از طریق ترکیب این احساسات  میتوان به احساسات پیچیده‌تری دست یافت. البته این مدل قابلیت استنتاج ریاضی ندارد و محاسباتی نیست و برای اینکه بتوان احساسات را ارزیابی کرد باید مدلی را استفاده کرد که قابلیت استنتاج ریاضی را داشته باشد مانند مدلی که Russell[[3]](#russell-ja-a-circumplex-model-of-affect-j-personal-soc-psychol-1980-39-1161-crossref) این مدل احساسات را به دو `بعد والانس` و `بعد برانگیختگی` تقسیم بندی می‌کند. محور والانس احساسات منفی و محور برانگیختگی احساسات مثبت را نشان میدهد و تفاوت این دو مدل در گسستگی و پیوسته بودن زیف احساسات است که مدل Russell مدلی پیوسته است و طیف بیشتری از احساسات را شامل می‌شود.

 از دشواری های دریافت و پردازش اطلاعات احساسی اینکه اطلاعات احساسی به راحتی تحت تاثیر نویز قرار میگیرند و از موارد دیگر اینکه افراد در بیان دقیق احساسات خود تقریبا همیشه احساس واقعی خود را پنهان می‌کنند یا اینکه بعضی افراد در برخی موارد وضعیت احساسی خود را درک نمی‌کنند یا در مواردی ریز‌تر می‌توان به اینکه افراد در برخورد دوباره با یک نوع محرک احساسی خاص می‌تواند احساسات متفاوتی را تجربه کند.

شناخت احساسات می‌تواند بر اساس تصاویر، صدا، متن و سایر سیگنال‌های فیزیولوژیکی که به راحتی جمع‌آوری می‌شوند (مانند مقاومت پوست، ضربان قلب و فشار خون) صورت گیرد. اما ی شناسایی دقیق وضعیت‌های احساسی پیچیده دشوار است.

داده‌های EEG روش ترجیحی برای مطالعه پاسخ مغز به محرک‌های احساسی هستند
مطالعات نشان داده‌اند که نواحی مختلف مغز در فعالیت‌های ادراکی و شناختی مختلف شرکت می‌کنند؛ برای مثال، لوب فرونتال با تفکر و آگاهی مرتبط است، در حالی که لوب تمپورال با پردازش اطلاعات پیچیده‌ای مانند چهره‌ها، صحنه‌ها، بوها و صداها مرتبط است. لوب پاریتال با یکپارچه‌سازی اطلاعات حسی مختلف و کنترل عملیاتی اشیاء مرتبط است و لوب اکسیپیتال با بینایی مرتبط است[[4]](#chanel-g-kierkels-jj-soleymani-m-pun-t-short-term-emotion-assessment-in-a-recall-paradigm-int-jhum-comput-stud-2009-67-607627-crossref)

 مطالعات زیادی نشان داده است که ادغام محرک‌های حسی ناهمگن می‌تواند الگوهای مغزی را تقویت می‌کند و در تشخیص درست احساسات کمک کننده است.

2. مروری بر شناسایی احساسات چندوجهی بر اساس BCI
2.1. aBCI چندوجهی
اطلاعات تک‌مدالیتی به راحتی تحت تاثیر انواع نویزهای مختلف قرار می‌گیرند. D'mello[[5]](#dmello-sk-kory-j-a-review-and-meta-analysis-of-multimodal-affect-detection-systems-acm-comput-surv-csur-2015-47-136-crossref) با استفاده از روش‌های آماری دقت شناسایی احساسات تک‌مدالیتی و چندوجهی را با استفاده از الگوریتم‌های مختلف و مجموعه داده‌های مختلف مقایسه کردبهترین سیستم شناسایی احساسات چندوجهی به دقت 85% رسید و به طور قابل توجهی دقیق‌تر از سیستم تک‌مدالیتی بود، با بهبود میانگین 9.83% (میانه 6.60%).این مطالعه نیز نشان داد که تلفیق مدالیتی کارآمد به طور قابل توجهی استحکام سیستم‌های شناسایی احساسات را بهبود می‌بخشد.

 احساسات معمولاً از طریق تعامل بین نوروفیزیولوژی و رفتار بیان می‌شوند؛مودالیت‌های ترکیبی که شامل مودالیت‌های فیزیولوژیکی و رفتاری خارجی هستند، توجه بیشتری از پژوهشگران شناسایی احساسات به خود جلب کرده‌اند. در میان مودالیت‌های اصلی رفتاری، سیگنال‌های ردیابی حرکت چشم و حالت چهره دو مودالیتی هستند که دارای اطلاعات حساس به محتوا هستند. حالات چهره، مستقیم‌ترین روش برای نمایان کردن احساسات هستند.[[1]](#he-z-li-z-yang-f-wang-l-li-j-zhou-c--pan-j-2020-advances-in-multimodal-emotion-recognition-based-on-braincomputer-interfaces-brain-sciences-1010-687-doi103390brainsci10100687)

 فرآیند شناسایی حالات چهره شامل سه مرحله است: شناسایی موقعیت چهره، استخراج ویژگی‌ها و طبقه‌بندی حالات. در بخش شناسایی موقعیت چهره، دو فناوری معمولاً استفاده می‌شوند: مبتنی بر ویژگی‌ها و مبتنی بر تصویر. رایج‌ترین روش‌های شناسایی احساسات برای حالات چهره، شناسایی ویژگی‌های هندسی و بافتی و شناسایی واحدهای عمل چهره هستند. حالات معمولاً به هفت حالت پایه‌ای تقسیم می‌شوند: ترس، تنفر، شادی، خشم، غم، شگفتی و تحقیر. اما حالت‌های احساسی انسان‌ها پیچیده‌اند و می‌توانند به ترکیبی از احساسات مختلف تقسیم شوند، شامل حالات پیچیده، حالات غیرعادی و میکروحالات.[[6]](#bakshi-u-singhal-r-a-survey-on-face-detection-methods-and-feature-extraction-techniques-of-facerecognition-int-j-emerg-trends-technol-comput-sci-2014-3-233237)

 سیگنال‌های حرکات چشم به ما اجازه می‌دهند که بفهمیم چه چیزی توجه کاربر را جلب کرده و رفتارهای ناخودآگاه او را مشاهده کنیم.
 سیگنال‌های حرکات چشم می‌توانند سیگنال غنی‌ای باشند که ویژگی‌های احساسی را منعکس می‌کنند، از جمله سه ویژگی پایه‌ای رایج: قطر مردمک، اطلاعات نگاه و سیگنال‌های ساکاد—همچنین ویژگی‌های آماری گسترش‌یافته، از جمله رویدادهای فرکانسی آماری و رویدادهای انحراف آماری. 
 اندازه مردمک با شناخت ارتباط دارد .زمانی که از حالت استراحت به حالت احساسی تحریک می‌شویم، اندازه مردمک‌هایمان به تبع آن تغییر می‌کند. تثبیت به موقعیت نسبتاً ثابت کره چشم در یک محدوده زمانی و فضایی خاص اشاره دارد. ساکاد به حرکات سریع چشم بین دو نقطه مورد علاقه (یا توجه) گفته می‌شود. با استفاده از این ویژگی‌های پایه‌ای سیگنال‌های حرکات چشم، می‌توانیم برانگیختگی و میزان مثبت‌نگری (والنس) افراد را از مقادیر آماری اطلاعات تثبیت و سیگنال‌های اسکن شناسایی کرده و از آن‌ها برای ارزیابی حالات درونی افراد استفاده کنیم.[[7]](#võ-mlh-jacobs-am-kuchinke-l-hofmann-m-conrad-m-schacht-a-hutzler-f-the-coupling-ofemotion-and-cognition-in-the-eye-introducing-the-pupil-oldnew-effect-psychophysiology-2008-45-130140crossref-pubmed)[[8]](#wang-c-a-munoz-dp-a-circuit-for-pupil-orienting-responses-implications-for-cognitive-modulation-ofpupil-size-curr-opin-neurobiol-2015-33-134140-crossrefpubmed)

 در [[9]](#zheng-w-l-liu-w-lu-y-lu-b-l-cichocki-a-emotionmeter-a-multimodal-framework-for-recognizing-human-emotions-ieee-trans-cybern-2018-49-11101122-crossref)، یک چارچوب چندوجهی به نام EmotionMeter برای تشخیص احساسات انسان با استفاده از شش الکترود EEG و عینک‌های ردیابی چشم ارائه شد. آزمایش‌های این مطالعه نشان داد که تکمیلی بودن EEG و حرکات چشم در تشخیص احساسات و استفاده از یک شبکه عصبی چندوجهی عمیق برای بهبود عملکرد تشخیص استفاده شده است. برای داده‌های EEG، در مرحله پیش‌پردازش، فیلتر پاس‌باند با فرکانس بین 1 تا 75 هرتز برای فیلتر کردن نویزهای غیرمرتبط استفاده شد. سپس از تبدیل فوریه کوتاه‌مدت بدون همپوشانی در پنج باند فرکانسی در هر کانال و در پنج باند فرکانسی برای استخراج چگالی طیفی قدرت (PSD) و آنتروپی تفاضلی (DE) استفاده شد. برای حرکات چشم، ویژگی‌های مختلفی از پارامترهای مختلف در ادبیات استخراج شد، مانند قطر دانه چشم، تثبیت، سکید و چشمک. از میان همه ویژگی‌های حرکات چشم، قطر دانه چشم بیشترین ارتباط مستقیم با وضعیت احساسی دارد، اما به راحتی تحت تأثیر روشنایی و سایه قرار می‌گیرد.

##### منابع

###### He, Z., Li, Z., Yang, F., Wang, L., Li, J., Zhou, C., & Pan, J. (2020). Advances in Multimodal Emotion Recognition Based on Brain–Computer Interfaces. Brain Sciences, 10(10), 687. doi:10.3390/brainsci10100687.

###### Ekman, P.E.; Davidson, R.J. The Nature of Emotion: Fundamental Questions; Oxford University Press: Oxford, UK, 1994.

###### Russell, J.A. A circumplex model of affect. J. Personal. Soc. Psychol. 1980, 39, 1161. [[CrossRef]](https://psycnet.apa.org/doiLanding?doi=10.1037/h0077714&)

###### Chanel, G.; Kierkels, J.J.; Soleymani, M.; Pun, T. Short-term emotion assessment in a recall paradigm. Int. J.Hum.-Comput. Stud. 2009, 67, 607–627. [[CrossRef]](https://linkinghub.elsevier.com/retrieve/pii/S1071581909000433)

###### D’mello, S.K.; Kory, J. A review and meta-analysis of multimodal affect detection systems. ACM Comput. Surv. (CSUR) 2015, 47, 1–36. [[CrossRef]](https://dl.acm.org/doi/10.1145/2682899)

###### Bakshi, U.; Singhal, R. A survey on face detection methods and feature extraction techniques of facerecognition. Int. J. Emerg. Trends Technol. Comput. Sci. 2014, 3, 233–237.

###### Võ, M.L.H.; Jacobs, A.M.; Kuchinke, L.; Hofmann, M.; Conrad, M.; Schacht, A.; Hutzler, F. The coupling ofemotion and cognition in the eye: Introducing the pupil old/new effect. Psychophysiology 2008, 45, 130–140.[[CrossRef]](http://dx.doi.org/10.1111/j.1469-8986.2007.00606.x) [[PubMed]](https://pubmed.ncbi.nlm.nih.gov/17910733/)

###### Wang, C.-A.; Munoz, D.P. A circuit for pupil orienting responses: Implications for cognitive modulation ofpupil size. Curr. Opin. Neurobiol. 2015, 33, 134–140. [[CrossRef]](http://dx.doi.org/10.1016/j.conb.2015.03.018) [[PubMed]](https://pubmed.ncbi.nlm.nih.gov/25863645/)

###### Zheng, W.-L.; Liu, W.; Lu, Y.; Lu, B.-L.; Cichocki, A. Emotionmeter: A multimodal framework for recognizing human emotions. IEEE Trans. Cybern. 2018, 49, 1110–1122. [[CrossRef]](https://ieeexplore.ieee.org/document/8283814)
